<style>
/* 局部样式，确保只影响 publications 区域 */
.pub-card {
  background: #fff;
  border: 1px solid #e1e4e8;
  border-radius: 8px;
  padding: 20px;
  margin-bottom: 20px;
  transition: all 0.2s ease;
  box-shadow: 0 2px 5px rgba(0,0,0,0.05);
}
.pub-card:hover {
  transform: translateY(-3px);
  box-shadow: 0 5px 15px rgba(0,0,0,0.1);
  border-color: #0366d6;
}
.pub-title {
  font-size: 1.1em;
  font-weight: 700;
  color: #0366d6;
  text-decoration: none;
  display: block;
  margin-bottom: 8px;
}
.pub-authors {
  color: #444;
  margin-bottom: 8px;
  font-size: 0.95em;
}
.pub-venue {
  color: #666;
  font-size: 0.9em;
  font-style: italic;
  margin-bottom: 12px;
}
.badge-group {
  display: flex;
  gap: 8px;
}
</style>

<div class="pub-card">
  <a href="http://arxiv.org/abs/2601.21626" class="pub-title">
    HeRo-Q: A General Framework for Stable Low Bit Quantization via Hessian Conditioning
  </a>
  <div class="pub-authors">
    <strong>Jinhao Zhang</strong>, Yunquan Zhang, Zicheng Yan, Boyang Zhang, Jun Sun, Daning Cheng
  </div>
  <div class="pub-venue">
    Preprint • Under Review for <strong style="color:#d73a49;">ICML 2026</strong> • Jan 2026
  </div>
  <div class="badge-group">
    <a href="http://arxiv.org/abs/2601.21626"><img src="https://img.shields.io/badge/arXiv-2601.21626-b31b1b?style=flat-square&logo=arxiv&logoColor=white" alt="arXiv"></a>
    <a href="http://arxiv.org/pdf/2601.21626"><img src="https://img.shields.io/badge/PDF-Download-00509e?style=flat-square&logo=adobe-acrobat-reader&logoColor=white" alt="PDF"></a>
  </div>
</div>

<div class="pub-card">
  <a href="http://arxiv.org/abs/2512.16282" class="pub-title">
    CALM: A CKA-Guided Adaptive Layer-Wise Modularization Framework for LLM Quantization
  </a>
  <div class="pub-authors">
    <strong>Jinhao Zhang</strong>, Yunquan Zhang, Daning Cheng, Jun Sun, Zicheng Yan
  </div>
  <div class="pub-venue">
    Preprint • Submitted to <strong style="color:#d73a49;">ACL 2026</strong> • Dec 2025
  </div>
  <div class="badge-group">
    <a href="http://arxiv.org/abs/2512.16282"><img src="https://img.shields.io/badge/arXiv-2512.16282-b31b1b?style=flat-square&logo=arxiv&logoColor=white" alt="arXiv"></a>
    <a href="http://arxiv.org/pdf/2512.16282"><img src="https://img.shields.io/badge/PDF-Download-00509e?style=flat-square&logo=adobe-acrobat-reader&logoColor=white" alt="PDF"></a>
  </div>
</div>

<div class="pub-card">
  <a href="http://arxiv.org/abs/2508.09204" class="pub-title">
    MoQE: Improve Quantization Model performance via Mixture of Quantization Experts
  </a>
  <div class="pub-authors">
    <strong>Jinhao Zhang</strong>, Yunquan Zhang, Boyang Zhang, Zeyu Liu, Daning Cheng
  </div>
  <div class="pub-venue">
    Preprint • Under Review for <strong style="color:#d73a49;">ICLR 2026</strong> • Aug 2025
  </div>
  <div class="badge-group">
    <a href="http://arxiv.org/abs/2508.09204"><img src="https://img.shields.io/badge/arXiv-2508.09204-b31b1b?style=flat-square&logo=arxiv&logoColor=white" alt="arXiv"></a>
    <a href="http://arxiv.org/pdf/2508.09204"><img src="https://img.shields.io/badge/PDF-Download-00509e?style=flat-square&logo=adobe-acrobat-reader&logoColor=white" alt="PDF"></a>
  </div>
</div>
